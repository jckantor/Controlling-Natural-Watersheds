{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--NOTEBOOK_HEADER-->\n",
    "*This notebook contains material from [Controlling-Natural-Watersheds](https://jckantor.github.io/Controlling-Natural-Watersheds);\n",
    "content is available [on Github](https://github.com/jckantor/Controlling-Natural-Watersheds.git).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--NAVIGATION-->\n",
    "< [Data Sources](http://nbviewer.jupyter.org/github/jckantor/Controlling-Natural-Watersheds/blob/master/notebooks/01.00-Data_Sources.ipynb) | [Contents](toc.ipynb) |<p><a href=\"https://colab.research.google.com/github/jckantor/Controlling-Natural-Watersheds/blob/master/notebooks/01.01-Water_Survey_of_Canada_HYDAT.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open in Google Colaboratory\"></a><p><a href=\"https://raw.githubusercontent.com/jckantor/Controlling-Natural-Watersheds/master/notebooks/01.01-Water_Survey_of_Canada_HYDAT.ipynb\"><img align=\"left\" src=\"https://img.shields.io/badge/Github-Download-blue.svg\" alt=\"Download\" title=\"Download Notebook\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Water Survey of Canada HYDAT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Historical data for lake levels and stream flows in the Rainy River watershed are available from several public sources including the [HYDAT database](https://www.ec.gc.ca/rhc-wsc/default.asp?lang=En&n=9018B5EC-1) from the [Water Survey of Canada (WSC)](http://wateroffice.ec.gc.ca/). The [HYDAT database](https://www.ec.gc.ca/rhc-wsc/default.asp?lang=En&n=9018B5EC-1) database consists of Microsoft Access .mdb file providing data on daily water flows and levels throughout Canada.\n",
    "\n",
    "For the purposes of these notebooks, individual tables (STATIONS, DLY_FLOWS, and DLY_LEVELS) were extracted from the database as .csv files with [MDB Explorer](http://www.mdbexplorer.com/). This notebook then reads the ..csv file to extract information relevant to the Rainy River basin and stores the results in this repository's data directory.  Due to size constraints , only the data relevant to the Rainy River Watershed is included in the repository. Neither the HYDAT database or extracted .csv files are included in this repository.\n",
    "\n",
    "This notebooks is run whenever a new version of the HYDAT database becomes available, normally on a quarterly basis, or if additional flow and level stations are needed in the repository data cache.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization and Loading of HYDAT Data Tables\n",
    "\n",
    "Load needed libaries and data tables from the HYDAT database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Standard Python modules\n",
    "import pandas as pd\n",
    "from IPython.core.display import display\n",
    "from IPython.display import IFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where data files have been stored\n",
    "HYDAT_dir = \"../data/HYDAT/csv/\"\n",
    "\n",
    "# Read data files as a pandas dataframes\n",
    "STATIONS = pd.read_csv(HYDAT_dir + 'STATIONS.csv', index_col = 0);\n",
    "DLY_LEVELS = pd.read_csv(HYDAT_dir + 'DLY_LEVELS.csv')\n",
    "DLY_FLOWS = pd.read_csv(HYDAT_dir + 'DLY_FLOWS.csv')\n",
    "\n",
    "print(\"    Stations in the HYDAT database = \", len(STATIONS.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoring Stations in the Rainy River Watershed\n",
    "\n",
    "The following cell creates a pandas dataframe of monitoring stations from the STATIONS.csv table extracted from the HYDAT database. The extaction searches for all stations with a specified region bounded by latitude and longitudes.\n",
    "\n",
    "For reference, this is a map of the [Rainy River drainage](http://www.ijc.org/files/tinymce/uploaded/rl_basinmap.pdf) basin available from the International Joint Commission. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IFrame(\"https://legacyfiles.ijc.org/tinymce/uploaded/rl_basinmap.pdf#toolbar=0&navpanes=0&scrollbar=0\",\n",
    "       width=700, height=540)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bounding region\n",
    "lngW = -94.0\n",
    "lngE = -90.5\n",
    "latS = 47.5\n",
    "latN = 49.0\n",
    "\n",
    "# find monitoring stations within bounding region\n",
    "stationList = STATIONS[\n",
    "    (STATIONS['LATITUDE'] >= latS) & \\\n",
    "    (STATIONS['LATITUDE'] <= latN) & \\\n",
    "    (STATIONS['LONGITUDE'] <= lngE) & \\\n",
    "    (STATIONS['LONGITUDE'] >= lngW)].index\n",
    "WSC_STATIONS = STATIONS.loc[stationList]\n",
    "\n",
    "DLY_LEVELS = DLY_LEVELS.loc[DLY_LEVELS['STATION_NUMBER'].isin(stationList)]\n",
    "DLY_FLOWS = DLY_FLOWS.loc[DLY_FLOWS['STATION_NUMBER'].isin(stationList)]\n",
    "\n",
    "# add columns to STATIONS for level and flow stations\n",
    "WSC_STATIONS['Level'] = ''\n",
    "WSC_STATIONS['Flow'] = ''\n",
    "\n",
    "# mark level and flow stations\n",
    "WSC_STATIONS.loc[set(DLY_LEVELS['STATION_NUMBER']).intersection(WSC_STATIONS.index),'Level'] = True\n",
    "WSC_STATIONS.loc[set(DLY_FLOWS['STATION_NUMBER']).intersection(WSC_STATIONS.index),'Flow'] = True\n",
    "\n",
    "print(\"Stations within region of interest = \", len(WSC_STATIONS.index))\n",
    "print(\"DLY_FLOWS records = \", len(DLY_FLOWS.index))\n",
    "print(\"DLY_LEVELS records = \", len(DLY_LEVELS.index))\n",
    "display(WSC_STATIONS.loc[:,['Level','Flow','STATION_NAME','LATITUDE','LONGITUDE',]])\n",
    "\n",
    "WSC_STATIONS.to_pickle('../data/WSC_STATIONS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickle Level Data to WSC_LEVELS\n",
    "\n",
    "Extract level data from the HYDAT database and pickle to WSC_LEVELS data set. The pickled dataframe is indexed by date, with columns tagged by station name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLevelsWSC(s):\n",
    "    '''Return a time series for levels at a given station.'''\n",
    "    ts = {}   \n",
    "    data = DLY_LEVELS[DLY_LEVELS['STATION_NUMBER'] == s]\n",
    "    for k in data.index:\n",
    "        mo = str(data.loc[k,'MONTH'])\n",
    "        yr = str(data.loc[k,'YEAR'])\n",
    "        for n in range(1,data.loc[k,'NO_DAYS']+1):\n",
    "            ts[pd.to_datetime(mo+'/'+str(n)+'/'+yr)] = data.loc[k,'LEVEL'+str(n)]  \n",
    "    ts = pd.Series(ts)\n",
    "    #drop initial and terminal null entries\n",
    "    j = 0\n",
    "    while j<len(ts.index) and pd.isnull(ts.iloc[j]):\n",
    "        j += 1\n",
    "    k = len(ts.index) - 1\n",
    "    while k>=j and pd.isnull(ts.iloc[k]):\n",
    "        k += -1\n",
    "    return ts[j:k+1]\n",
    "\n",
    "WSC_LEVELS = pd.DataFrame({s:getLevelsWSC(s) for s in WSC_STATIONS[WSC_STATIONS['Level']==True].index})\n",
    "WSC_LEVELS.to_pickle('../data/WSC_LEVELS')\n",
    "WSC_LEVELS.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickle Flow Data to WSC_FLOWS\n",
    "\n",
    "The DLY_FLOW data is encoded in an irregular tabular format where rows are indexed by station code, year, and month, and columns are indexed by date.  Given a station code, the following function decodes DLY_FLOW to produce a pandas times series of flow rates.  The function is used to create a pandas dataframe for all flow stations in WSC_STATIONS, then pickles the results to a data file for use by other notebooks in this repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFlowsWSC(s):\n",
    "    ts = {}\n",
    "    data = DLY_FLOWS[DLY_FLOWS['STATION_NUMBER'] == s]\n",
    "    for k in data.index:\n",
    "        mo = str(data.loc[k,'MONTH'])\n",
    "        yr = str(data.loc[k,'YEAR'])\n",
    "        for n in range(1,data.loc[k,'NO_DAYS']+1):\n",
    "            ts[pd.to_datetime(mo+'/'+str(n)+'/'+yr)] = data.loc[k,'FLOW'+str(n)]  \n",
    "    ts = pd.Series(ts)\n",
    "    ts.name = s +': ' + STATIONS.loc[s,'STATION_NAME'] + \\\n",
    "        ' from ' + '{0}'.format(ts.index[0].year) + \\\n",
    "        ' to ' + '{0}'.format(ts.index[-1].year)\n",
    "    #drop initial and terminal null entries\n",
    "    j = 0\n",
    "    while j<len(ts.index) and pd.isnull(ts.iloc[j]):\n",
    "        j += 1\n",
    "    k = len(ts.index) - 1\n",
    "    while k>=j and pd.isnull(ts.iloc[k]):\n",
    "        k += -1\n",
    "    return ts[j:k+1]\n",
    "\n",
    "WSC_FLOWS = pd.DataFrame({s: getFlowsWSC(s) for s in WSC_STATIONS[WSC_STATIONS['Flow']==True].index})\n",
    "WSC_FLOWS.to_pickle('../data/WSC_FLOWS')\n",
    "WSC_FLOWS.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--NAVIGATION-->\n",
    "< [Data Sources](http://nbviewer.jupyter.org/github/jckantor/Controlling-Natural-Watersheds/blob/master/notebooks/01.00-Data_Sources.ipynb) | [Contents](toc.ipynb) |<p><a href=\"https://colab.research.google.com/github/jckantor/Controlling-Natural-Watersheds/blob/master/notebooks/01.01-Water_Survey_of_Canada_HYDAT.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open in Google Colaboratory\"></a><p><a href=\"https://raw.githubusercontent.com/jckantor/Controlling-Natural-Watersheds/master/notebooks/01.01-Water_Survey_of_Canada_HYDAT.ipynb\"><img align=\"left\" src=\"https://img.shields.io/badge/Github-Download-blue.svg\" alt=\"Download\" title=\"Download Notebook\"></a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
